{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ValeryiaPilchuk/Assignment-3-EquationofaSlime/blob/master/Assignment%203%20-%20Valeryia%20Pilchuk.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "Mg2ebThRKskQ"
   },
   "outputs": [],
   "source": [
    "# Imports section\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W07hbCq_KskR"
   },
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "QFRLdBbQKskR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Temperature °C  Mols KCL     Size nm^3\n",
      "0              469       647  6.244743e+05\n",
      "1              403       694  5.779610e+05\n",
      "2              302       975  6.196847e+05\n",
      "3              779       916  1.460449e+06\n",
      "4              901        18  4.325726e+04\n",
      "5              545       637  7.124634e+05\n",
      "6              660       519  7.006960e+05\n",
      "7              143       869  2.718260e+05\n",
      "8               89       461  8.919803e+04\n",
      "9              294       776  4.770210e+05\n",
      "10             991       117  2.441771e+05\n",
      "11             307       781  5.006455e+05\n",
      "12             206        70  3.145200e+04\n",
      "13             437       599  5.390215e+05\n",
      "14             566        75  9.185271e+04\n",
      "<bound method DataFrame.info of      Temperature °C  Mols KCL     Size nm^3\n",
      "0               469       647  6.244743e+05\n",
      "1               403       694  5.779610e+05\n",
      "2               302       975  6.196847e+05\n",
      "3               779       916  1.460449e+06\n",
      "4               901        18  4.325726e+04\n",
      "..              ...       ...           ...\n",
      "995             894       847  1.545661e+06\n",
      "996             327       982  6.737041e+05\n",
      "997             791       213  3.477543e+05\n",
      "998             769       553  8.684794e+05\n",
      "999             919       452  8.476413e+05\n",
      "\n",
      "[1000 rows x 3 columns]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature °C</th>\n",
       "      <th>Mols KCL</th>\n",
       "      <th>Size nm^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>471.530000</td>\n",
       "      <td>5.086111e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "      <td>288.482872</td>\n",
       "      <td>4.474838e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.611429e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>250.750000</td>\n",
       "      <td>226.750000</td>\n",
       "      <td>1.298267e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500.500000</td>\n",
       "      <td>459.500000</td>\n",
       "      <td>3.827182e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>750.250000</td>\n",
       "      <td>710.250000</td>\n",
       "      <td>7.603211e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.972127e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature °C     Mols KCL     Size nm^3\n",
       "count     1000.000000  1000.000000  1.000000e+03\n",
       "mean       500.500000   471.530000  5.086111e+05\n",
       "std        288.819436   288.482872  4.474838e+05\n",
       "min          1.000000     1.000000  1.611429e+01\n",
       "25%        250.750000   226.750000  1.298267e+05\n",
       "50%        500.500000   459.500000  3.827182e+05\n",
       "75%        750.250000   710.250000  7.603211e+05\n",
       "max       1000.000000  1000.000000  1.972127e+06"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "url = \"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\"\n",
    "data = pd.read_csv(url)\n",
    "# Output the first 15 rows of the data\n",
    "print(data.head(15))\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print(data.info)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKsDGIzBKskS"
   },
   "source": [
    "## Part 2. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "yY_tpQ4iKskS"
   },
   "outputs": [],
   "source": [
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "X = data[[\"Temperature °C\", \"Mols KCL\"]]\n",
    "y = data[\"Size nm^3\"]\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TScwdW0CKskT"
   },
   "source": [
    "## Part 3. Perform a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Fmvo9GOIKskU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample datapoint 294, 776: \n",
      " [641825.44020401]\n",
      "Score: \n",
      " 0.8607060208080753\n",
      "Coefficients: \n",
      " [ 875.90992708 1031.59502452]\n",
      "Intercept: \n",
      " -416209.8173862048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "reg = LinearRegression().fit(X, y)\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "print(\"Sample datapoint 294, 776: \\n\", reg.predict(np.array([[294, 776]])))\n",
    "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "print(\"Score: \\n\", reg.score(X, y))\n",
    "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "print(\"Coefficients: \\n\", reg.coef_)\n",
    "print(\"Intercept: \\n\", reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "\n",
    "The score for the model is 0.86071. This score is \"the coefficient of determination of the prediction\". In other words, the score is the accuracy of our linear model based on the data we have provided it.\n",
    "\n",
    "### Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "\n",
    "h(x) = 875.90992$x_1$ + 1031.59502$x_2$ - 416209.81739\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcXCTas1KskV"
   },
   "source": [
    "## Part 4. Use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "U_T44kr0KskW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for 30 cv values are: \n",
      " [0.75886543 0.83285827 0.84503685 0.89271751 0.87905771 0.8226239\n",
      " 0.82596983 0.8860083  0.87968748 0.87808515 0.87500422 0.83763716\n",
      " 0.89971607 0.84149677 0.87262014 0.82884345 0.86958288 0.7630771\n",
      " 0.90621861 0.866835   0.86477267 0.85435504 0.88700702 0.83886377\n",
      " 0.77366306 0.68806535 0.85564619 0.89361746 0.87811057 0.87748462]\n",
      "The scores for 10 cv values are: \n",
      " [0.81123596 0.86440978 0.87808742 0.86561069 0.87495621 0.84484397\n",
      " 0.87941022 0.86349411 0.78353682 0.88686516]\n"
     ]
    }
   ],
   "source": [
    "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
    "scores = cross_val_score(reg, X, y, cv=30)\n",
    "# Report on their finding and their significance\n",
    "print(\"The scores for 30 cv values are: \\n\", scores)\n",
    "scores = cross_val_score(reg, X, y, cv=10)\n",
    "print(\"The scores for 10 cv values are: \\n\", scores)\n",
    "prediction = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross validation we can see that the scores vary more as the cv value is increased. When the cv is 10, the scores vary only slightly, with only one values below 0.8 and all values below 0.9. When the cv value is increased to 30, the scores vary largely with the highest being above 0.9 and the lowest being below 0.7. The variety of the scores varies but is still acceptable as we do not want a value that is overfitted or underfitted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq_uaqQAKskW"
   },
   "source": [
    "## Part 5. Using Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "j6wsqhkrKskX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 0.00000000e+00  1.20000000e+01 -1.23111539e-07 -1.05648823e-11\n",
      "  2.00000000e+00  2.85714287e-02]\n",
      "Intercept: \n",
      " 1.6572012100368738e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.75886543, 0.83285827, 0.84503685, 0.89271751, 0.87905771,\n",
       "       0.8226239 , 0.82596983, 0.8860083 , 0.87968748, 0.87808515,\n",
       "       0.87500422, 0.83763716, 0.89971607, 0.84149677, 0.87262014,\n",
       "       0.82884345, 0.86958288, 0.7630771 , 0.90621861, 0.866835  ,\n",
       "       0.86477267, 0.85435504, 0.88700702, 0.83886377, 0.77366306,\n",
       "       0.68806535, 0.85564619, 0.89361746, 0.87811057, 0.87748462])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "poly = poly_reg.fit(X_poly,y)\n",
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(X_poly,y)\n",
    "# Report on the metrics and output the resultant equation as you did in Part 3.\n",
    "print(\"Coefficients: \\n\", lin_reg2.coef_)\n",
    "print(\"Intercept: \\n\", lin_reg2.intercept_)\n",
    "scores = cross_val_score(lin_reg2, X, y, cv=30)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of the model\n",
    "\n",
    "The cross value scores are very similar to the first linear regression model that we have made, this means that both of the models create a similar outcome for test data with similar accuracy. There are 6 coeffients in this model instead of 2 which set up the equation for the polynomial regression. The intercept for this model is also a lot lower than the interept for the linear regression model because of the general shape of this model. \n",
    "\n",
    "### Equation for the polynomial regression\n",
    "\n",
    "y = 12$x_1$ -1.23111$^-7$$x_2$$^2$ - 1.05649$^-11$$x_3$$^3$ + 2$x_4$$^4$ + 2.85714$^-2$$x_5$$^5$ \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "a3_sample_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
